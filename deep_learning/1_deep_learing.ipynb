{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5112619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([0,1], [1,0], '*', color='green')\n",
    "plt.plot([0,1],[0,1], 'x', color='blue')\n",
    "\n",
    "x = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "y = np.array([0,0,1,1]).reshape((-1,1))\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5233561",
   "metadata": {},
   "source": [
    "异或(XOR)问题：按照逻辑学的解释，如果两个条件中任意一个为True，结果为True，如果两个条件都是True或都是False，结果为False。直观理解，将这四中情况在平面上展示出来，设定True=1,False=0,平面中4个点： (1:0,1),(1:1,0),(0:0,0),(0:1,1).\n",
    "\n",
    "上一节我们的logisti回归是找到一条直线，将平面里两种不同的点分割开来，而对于异或问题中的4个点，无论如何**找不到一条直线，将这2类点完美分割开来**。解决这类问题，就需要引入深度网络。\n",
    "\n",
    "深层网络，复合函数 g(f(x)), 让输入经过一个函数f，产出的结果再输入到另外一个函数g。如果两个函数都是线性的，得到复合函数也是线性的，仍然无法解决上面的问题，添加一些激活函数，让复合函数不再是简单的线性了。\n",
    "\n",
    "神经网络本质是多项式回归， DNN只要足够复杂，就能拟合任何一个多项式。\n",
    "\n",
    "反向传播算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个Xor的模型\n",
    "class XOrModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(XOrModel, self).__init__()\n",
    "        hidden_dim = 2\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim,bias=True)  \n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim,bias=True)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.linear_1(x))\n",
    "#         out = torch.nn.functional.relu(self.linear_1(x))\n",
    "        out = self.linear_2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def get_y(self,x):\n",
    "        out = torch.sigmoid(self.linear_1(x))\n",
    "#         out = torch.nn.functional.relu(self.linear_1(x))\n",
    "        out = self.linear_2(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = XOrModel(2, 1) #模型初始化\n",
    "criterion = nn.BCELoss() #定义损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #定义最优化算法\n",
    "\n",
    "inX = torch.as_tensor(x,dtype=torch.float32) #将numpy转成tensor\n",
    "outY = torch.as_tensor(y,dtype=torch.float32)\n",
    "print(inX.shape)\n",
    "print(outY)\n",
    "\n",
    "predict_Y = model(inX) #根据输入获得当前参数下的输出值\n",
    "loss = criterion(predict_Y, outY) #计算误差\n",
    "print('loss {}'.format(loss.item()))\n",
    "\n",
    "for epoch in range(50):  #迭代次数\n",
    "    optimizer.zero_grad() #清理模型里参数的梯度值\n",
    "    predict_Y = model(inX) #根据输入获得当前参数下的输出值\n",
    "    loss = criterion(predict_Y, outY) #计算误差\n",
    "    loss.backward() #反向传播，计算梯度，\n",
    "    optimizer.step() #更新模型参数\n",
    "#     if epoch % 50 ==0:\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "\n",
    "print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
    "\n",
    "delta = 1e-7\n",
    "print(\"state_dict:\",model.state_dict())\n",
    "\n",
    "plt.plot([0,1], [1,0], '*', color='green')\n",
    "plt.plot([0,1],[0,1], 'x', color='blue')\n",
    "\n",
    "\n",
    "# 怎么画出分割面，还是没搞懂，待琢磨\n",
    "model_params = list(model.parameters())\n",
    "print(model_params)\n",
    "model_weights = model_params[0].data.numpy()\n",
    "model_bias = model_params[1].data.numpy()\n",
    "\n",
    "x_1 = np.arange(-0.1, 1.1, 0.1)\n",
    "y_1 = ((x_1 * model_weights[0,0]) + model_bias[0]) / (-model_weights[0,1])\n",
    "plt.plot(x_1, y_1)\n",
    "\n",
    "x_11 = np.arange(-0.1, 1.1, 0.1)\n",
    "y_11 = ((x_11 * model_weights[1,0]) + model_bias[0]) / (-model_weights[1,1])\n",
    "plt.plot(x_11, y_11)\n",
    "\n",
    "# x_2 = np.arange(-0.1, 1.1, 0.1)\n",
    "# y_2 = ((x_2 * model_weights[1,0]) + model_bias[1]) / (-model_weights[1,1])\n",
    "# plt.plot(x_2, y_2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_11 = np.arange(-0.1, 1.1, 0.001)\n",
    "tmp = np.zeros_like(x_11)\n",
    "print(x_11,tmp)\n",
    "print(\"``````\")\n",
    "tt = np.concatenate((x_11.reshape((-1,1)),tmp.reshape(-1,1)),axis=1)\n",
    "print(tt)\n",
    "y = model(torch.tensor(tt,dtype=torch.float32))\n",
    "# print()\n",
    "y1 = y.data.numpy().flatten()\n",
    "\n",
    "plt.plot([0,1], [1,0], '*', color='green')\n",
    "plt.plot([0,1],[0,1], 'x', color='blue')\n",
    "plt.plot(x_11,y1, '.', color='blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c19b39f",
   "metadata": {},
   "source": [
    "y = w1*x**2 + w2*x + b ,深度网络对于多项式的拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906ba2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
