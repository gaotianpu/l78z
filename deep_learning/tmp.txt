

一、
深度学习需要跟大量的数字打交道，先认识下4种类型的数字组织形式
1. 标量 scalar, 就是一个个具体的数字，1，1.2这类的, 整数，小数，直线上的点
2. 向量 vector ，n维向量，标量可以看成一个 1维向量，一条直线上的点， 2维向量[1,2], 平面坐标系中点，3维向量立体空间中的某个点， 超过3维，无法直观的映射，深度学习中的向量通常维度都会比较大。例如一个人，身高170cm，体重69kg，数学成绩98，语文成绩92，这个人的所有属性就构成一个向量,[170,69,98,92]. 
3. 矩阵 matrix ，矩阵是一个表格，多个向量构成一个矩阵，例如，平面上的n个点，[[1,2],[3,4],[1,7]], 一个班有n个同学，n,m 矩阵
4. 张量 tensor ，有时候描述一个东西，一个彩色图像，RGB三个通道，每个通道又是一个w*h的矩阵？（这种描述对么？）

numpy 表示这4种方式：
import numpy as np
scalar = 1.2
vector = np.array([1.0,2.1,3.2],dtype=numpy.float)
print(vector.shape)
matrix = np.array([[1,2,3],[4,5,6]]) 
print(matrix.shape)
tensor = np.array([[[1,2,3],[4,5,6]],[[1,2,3],[4,5,6]],[[1,2,3],[4,5,6]]])
print(tensor.shape)



二、线性回归 linear regression
深度学习的基础，需要掌握线性回归的概念
一堆平面上的点，是按照什么规律生成的？ y=w*x+b+random(), 如何确定w,b的值是多少？

输入值是x，预测值是y，
先随机找个w,b, 算出个predict_y
真实值和预测值差值最小的时候，意味着w,b就接近真实的值了。
power(y-predict_y), 当这个值最小的时候。
每次调整w，b时候，怎么知道是增加值，还是减少值，每次增加或减少的值是多少比较合适？

损失函数：均方误差函数，
求偏导数.
随机梯度下降SGD。

y = w0*x0+w1*x1+w2*x2+w3*x3 .... b 生成一堆随机数，
y = W*X 矩阵操作
矩阵操作

普通实现
numpy矩阵实现
pytorch,paddlepaddle的封装？

三、逻辑回归
softmax，
交叉熵

numpy矩阵实现
pytorch,paddlepaddle的封装？


四、多层神经网络
异或问题
二次多项式的拟合？
激活函数
反向传播


五、深度网络，mnist

六、卷积网络
卷积、激活函数，池化
过拟合正则：批归一化、正则项，dropout







